{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from ctokenizer import CTokenizer\n",
    "\n",
    "tokenizer = CTokenizer()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=2**15, embedding_dim=96)\n",
    "        self.gru = nn.GRU(input_size=96, hidden_size=96, batch_first=True)\n",
    "        self.classifier = nn.Linear(96, 100)\n",
    "\n",
    "    def forward(self, ids, last_elements, return_last_state=False):\n",
    "        \"\"\" ids: [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = ids.shape[0]\n",
    "\n",
    "        # [batch_size, seq_len, emb_dim]\n",
    "        emb = self.embedding(ids)\n",
    "\n",
    "        # [batch_size, seq_len, emb_dim]\n",
    "        features, _ = self.gru(emb)\n",
    "\n",
    "        last_feature = features[range(batch_size), last_elements]\n",
    "\n",
    "        # [batch_size, hid_dim] -> [batch_size, 100]\n",
    "        logits = self.classifier(last_feature)\n",
    "\n",
    "        if return_last_state:\n",
    "            return logits, last_feature\n",
    "\n",
    "        return logits\n",
    "\n",
    "state_dict = torch.load(\"gru_weights2/model_79.pth\", map_location=\"cpu\")\n",
    "model = Network()\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = state_dict[\"embedding.weight\"]\n",
    "\n",
    "weights_i = state_dict[\"gru.weight_ih_l0\"]\n",
    "weights_h = state_dict[\"gru.weight_hh_l0\"]\n",
    "\n",
    "bias_i = state_dict[\"gru.bias_ih_l0\"]\n",
    "bias_h = state_dict[\"gru.bias_hh_l0\"]\n",
    "\n",
    "classifier_weight = state_dict[\"classifier.weight\"]\n",
    "classifier_bias = state_dict[\"classifier.bias\"]\n",
    "\n",
    "classifier_weight = torch.nn.functional.pad(classifier_weight, (0, 0, 0, 4))\n",
    "classifier_bias = torch.nn.functional.pad(classifier_bias, (0, 4), value=-torch.inf)\n",
    "\n",
    "embeddings_ = embeddings @ weights_i.T + bias_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings, hidden_dim = embeddings.shape\n",
    "num_classes, = classifier_bias.shape\n",
    "\n",
    "with open(\"solution/resources/gru_weights2.bin\", \"wb\") as file:\n",
    "    file.write(hidden_dim.to_bytes(length=4, byteorder=\"little\"))\n",
    "    file.write(num_embeddings.to_bytes(length=4, byteorder=\"little\"))\n",
    "    file.write(num_classes.to_bytes(length=4, byteorder=\"little\"))\n",
    "    \n",
    "    file.write(embeddings_.numpy().tobytes())\n",
    "    file.write(weights_h.numpy().tobytes())\n",
    "    file.write(bias_h.numpy().tobytes())\n",
    "\n",
    "    file.write(classifier_weight.numpy().tobytes())\n",
    "    file.write(classifier_bias.numpy().tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(96)\n",
    "x = tokenizer.encode(\"print(\\\"Hello, world!\\\")\\n\")\n",
    "\n",
    "for i in x:\n",
    "    rzn_i = embeddings_[i]\n",
    "    # rzn_i = bias_i + weights_i @ e\n",
    "    rzn_h = bias_h + weights_h @ h\n",
    "    rz = torch.sigmoid(rzn_i[:2*96] + rzn_h[:2*96])\n",
    "    n = torch.tanh(rzn_i[2*96:] + rz[:96] * rzn_h[2*96:])\n",
    "    h = (1 - rz[96:]) * n + rz[96:] * h\n",
    "\n",
    "output = classifier_bias + classifier_weight @ h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6589, -0.2389, -1.4574, -0.5617, -0.2824,  0.6322, -0.0603, -0.3864,\n",
      "        -1.6901,  0.1955])\n",
      "tensor([-1.2136, -2.5133, -0.5410, -3.4197, -1.5178, -0.4936, -4.3799, -3.4258,\n",
      "        -0.5711,  0.1148])\n",
      "tensor([-0.0268,  0.0835,  0.1727,  0.2376,  0.1116,  0.1489,  0.2497,  0.1452,\n",
      "         0.0182, -0.0504])\n",
      "tensor([ 0.0706,  0.1254,  0.6507,  0.2384,  0.3526, -0.5223, -0.2796,  0.5353,\n",
      "        -0.8297, -0.2017])\n"
     ]
    }
   ],
   "source": [
    "print(e[:10])\n",
    "print(rzn_i[:10])\n",
    "print(rzn_h[:10])\n",
    "print(h[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6589, -0.2389, -1.4574, -0.5617, -0.2824,  0.6322, -0.0603, -0.3864,\n",
      "        -1.6901,  0.1955])\n",
      "tensor([-1.2136, -2.5133, -0.5410, -3.4197, -1.5178, -0.4936, -4.3799, -3.4258,\n",
      "        -0.5711,  0.1148])\n",
      "tensor([-0.0268,  0.0835,  0.1727,  0.2376,  0.1116,  0.1489,  0.2497,  0.1452,\n",
      "         0.0182, -0.0504])\n",
      "tensor([ 0.0706,  0.1254,  0.6507,  0.2384,  0.3526, -0.5223, -0.2796,  0.5353,\n",
      "        -0.8297, -0.2017])\n"
     ]
    }
   ],
   "source": [
    "print(e[:10])\n",
    "print(rzn_i[:10])\n",
    "print(rzn_h[:10])\n",
    "print(h[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(75)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.1370, -12.9131,  -2.6255,  -2.5055,  -6.0172,   1.2686, -12.8175,\n",
       "          -0.8780,  -0.3550,  -2.4557,   3.0256,   4.2143,   1.9403,  -2.6419,\n",
       "          -4.2999,   0.8922,  -4.3181,  -4.0606,  -2.3016,   0.5230, -12.9406,\n",
       "          -1.2455,  -0.5309,  -4.6550,  -3.2385,  -1.3632,  -2.5301,   0.9723,\n",
       "          -3.9741,  -6.7590,   1.6380,   0.5815,   0.2733, -13.0002,  -2.5879,\n",
       "           1.3441, -12.8627, -12.9307,  -1.7153,   3.3323,  -3.7203,   0.2743,\n",
       "          -3.6626,  -0.4977,  -0.2695, -12.8957,   1.7998,  -5.9528,  -1.0700,\n",
       "          -1.5789,  -5.2057,   3.8470, -13.0275,   1.7345,  -1.8308,  -2.2166,\n",
       "         -12.7927,   3.8284,  -1.8637,   2.3391,   1.3699,  -6.7306,   0.8004,\n",
       "          -1.3970,  -2.5148, -13.1093,   0.5474,  -0.3931,  -3.7620, -12.7709,\n",
       "          -4.3564,   2.7505,  -5.8263,   3.8869,  -4.0820,   4.6155,  -2.1625,\n",
       "          -3.7223,  -1.8967,  -2.3610,  -2.7317,  -0.8835,  -2.9204,  -0.8718,\n",
       "          -1.1453,  -4.9039,  -0.5078,   4.1140,  -5.9892,  -4.9300,   2.7172,\n",
       "          -2.0632,  -0.5132,  -6.8814,   0.4789,  -0.0663,   0.1393,   0.8700,\n",
       "          -8.0717,  -3.2356]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(x).reshape(1, -1), len(x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
